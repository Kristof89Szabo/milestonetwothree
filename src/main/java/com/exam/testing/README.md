### Common vocabulary for testing

- <u>Test Case</u> - A set of utructions, conditions, or requirements used to test a specific feature or functionality
  of a software application.
- <u>Test Suite</u> - A collection of test cases that are grouped together to test a specific area or function of a
  software application.
- <u>Test Plan</u> - A detailed document that outlines the testing approach, goals, objectives, and resources required
  to ensure that the software application meets the desired quality standards.
- <u>Test Scenario</u> - A hypothetical situation or use case that is used to test the functionality of a software
  application.
- <u>Test Script</u> - A set of utructions that are executed automatically to perform a specific test case or test
  scenario.
- <u>Test Environment</u> - The hardware and software infrastructure that is used to execute tests on a software
  application.
- <u>Test Data</u> - The input data that is used to execute a test case or test scenario.
- <u>Test Result</u> - The output generated by executing a test case or test scenario, which indicates whether the
  software application passed or failed the test.
- <u>Regression Testing</u> - Testing performed to ensure that changes or updates to a software application do not
  affect its existing functionality.
- <u>Smoke Testing</u> - A preliminary test that is performed to ensure that the basic functionality of a software
  application is working correctly before proceeding with more comprehensive testing.

### Fundamental concepts of software testing

- Testing is an iterative process - Testing is not a one-time activity but an iterative process that involves repeated
  testing of the software application as new changes and updates are made to it.


- Testing should begin early in the software development lifecycle - Testing should be integrated into the software
  development lifecycle from the early stages to ensure that defects are identified and fixed as early as possible.


- Testing aims to find defects - The primary objective of testing is to find defects or errors in the software
  application and ensure that they are fixed before the application is released.


- Testing should be based on requirements - Testing should be based on the requirements of the software application to
  ensure that it meets the desired quality standards.


- Testing should be both manual and automated - Testing can be performed manually by humans or automated using software
  tools, and both approaches have their advantages and disadvantages.


- Test coverage should be comprehensive - Testing should cover all aspects of the software application, including
  functional, non-functional, and performance aspects, to ensure that it meets the desired quality standards.


- Testing should be repeatable and consistent - Testing should be performed in a repeatable and consistent manner to
  ensure that the results are consistent and reliable.


- Testing should be prioritized - Testing should be prioritized based on the criticality and impact of the features or
  functions being tested.


- Test results should be documented - Test results should be documented to ensure that defects are tracked and fixed,
  and the testing process is improved over time.


- Testing is not exhaustive - Testing cannot guarantee that all defects in the software application are identified, but
  it can increase the confidence in the quality of the application.

### Established techniques for designing tests

- Boundary Value Analysis (BVA) - This technique involves testing the boundaries or limits of input values to ensure
  that the software application handles them correctly. For example, testing how the application handles values just
  below and above a particular limit.


- Equivalence Partitioning (EP) - This technique involves dividing the input data into equivalent classes or partitions
  and testing each partition to ensure that the application handles all variations of the input data correctly.


- Decision Table Testing - This technique involves creating a table that lists all possible combinations of inputs and
  outputs for a specific feature or function of the software application. The table is then used to design test cases
  that cover all possible scenarios.


- State Transition Testing - This technique involves testing the software application's behavior as it transitions
  between different states or modes. For example, testing how the application handles different user inputs when
  transitioning from one screen to another.


- Exploratory Testing - This technique involves exploring the software application's features and functions to identify
  defects or errors that may not be identified through other testing techniques. It involves using the software
  application as a user would to identify any unexpected or unusual behavior.


- Risk-based Testing - This technique involves identifying and prioritizing the risks associated with different features
  or functions of the software application and designing test cases that cover those risks.


- Error Guessing - This technique involves designing test cases based on the tester's intuition and experience to
  identify defects or errors that may not be identified through other testing techniques. It involves imagining
  scenarios that may cause errors and designing test cases to simulate those scenarios.


- Pairwise Testing - This technique involves testing all possible combinations of pairs of input parameters to identify
  any defects or errors that may not be identified through other testing techniques. It aims to minimize the number of
  test cases required while still achieving comprehensive test coverage.